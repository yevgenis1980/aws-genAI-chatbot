<img width="800" height="533" alt="image" src="https://github.com/user-attachments/assets/f0275285-60aa-46b6-8749-e11bf059ac08" />


## AWS | GenAI Chatbot
AWS GenAI LLM Chatbot is an openâ€‘source, enterpriseâ€‘ready generative AI chatbot solution that you can deploy in your own AWS account. Itâ€™s designed to let you build powerful chatbots that combine large language models (LLMs) and Retrievalâ€‘Augmented Generation (RAG) â€” meaning it can answer questions using both the modelâ€™s capabilities and relevant content from indexed documents stored in your AWS environment



ğŸ¯ Architecture Overview
```
âœ… VPC + Subnets + NAT
âœ… Lambda backend + RAG pipeline + Embeddings
âœ… Bedrock integration (Claude, Titan, etc.)
âœ… DynamoDB chat history
âœ… OpenSearch vector search
âœ… AppSync GraphQL API
âœ… Cognito authentication
âœ… S3 + CloudFront frontend
âœ… Observability with CloudWatch and X-Ray
âœ… CI/CD GitHub Actions
âœ… Cost and security controls
```


ğŸš€ Key Features
```
ğŸ”¹ Multiâ€‘LLM Support
You can run many different models â€” including Amazon Bedrock models (like Claude and Llama 2), SageMaker hosted models, and even external provider models (OpenAI, Anthropic, Cohere, etc.) â€” all from a single chatbot framework.
ğŸ”¹ RAG Workspaces & Document Indexing
Upload files or text into â€œworkspacesâ€ and the system will index them so the chatbot can pull in relevant context during conversations. You choose the embeddings model and chunking setup.
ğŸ”¹ Multimodal Support
You can experiment with multimodal models (e.g., those that understand image content) via Amazon SageMaker deployments.
ğŸ”¹ Full Web UI Included
A Reactâ€‘based web interface is part of the solution, served from Amazon S3 & CloudFront, so end users can interact with the chatbot in a browser.
ğŸ”¹ Roleâ€‘Based Access Control
Use Amazon Cognito to manage user authentication and roles, letting you restrict which chatbots or data different users can access.
ğŸ”¹ Multiâ€‘Model Comparison
The system supports sending the same query to multiple models at once so you can compare how each responds in the same context
```



ğŸš€ Deployment Options
```
terraform init
terraform validate
terraform plan -var-file="template.tfvars"
terraform apply -var-file="template.tfvars" -auto-approve
```

